from moviepy.editor import AudioFileClip, concatenate_videoclips, concatenate_audioclips
from gtts import gTTS
import os
from .splitter import split_script_by_sentences
from .video_clip import create_slide_clip
from .cleaner import delete_temp_files
from .tts_google import synthesize_speech
import re

# ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì²˜ë¦¬í•˜ì—¬ ë™ì˜ìƒì„ ìƒì„±í•©ë‹ˆë‹¤.
def process_script(script, image_paths, font_color="white", font_size="medium", speaker_settings=None):
    print("ğŸ”¨ ì˜ìƒ ìƒì„± ì¤‘...")
    for path in image_paths:
        if not os.path.exists(path):
            raise FileNotFoundError(f"ì´ë¯¸ì§€ ê²½ë¡œ ì—†ìŒ: {path}")
    
    # 1. ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì—¬ëŸ¬ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
    lines = split_script_by_sentences(script)  
    clips = []
    audio_clips = []
    
    current_speaker = 'A'  # ê¸°ë³¸ í™”ì
    temp_audio_paths = [] # ì˜¤ë””ì˜¤ ì´ ê¸¸ì´ë¥¼ ì•Œê¸°ìœ„í•œ temp

    for idx, line in enumerate(lines):
        # ğŸ§  í™”ì êµ¬ë¶„ (ì˜ˆ: A: ~~)
        match = re.match(r'^([A-Z]):\s*(.+)', line)
        if match:
            speaker, content = match.groups()
            current_speaker = speaker
        else:
            content = line
            speaker = current_speaker  # ì´ì „ í™”ì ìœ ì§€


        voice_info = speaker_settings.get(speaker, {
            'lang': 'ko-KR',
            'gender': 'FEMALE',
            'voice': 'ko-KR-Wavenet-A'
        })

        # ğŸ—£ï¸ ê°œë³„ gTTS ìƒì„±
        # tts = gTTS(text=content, lang=voice_info['lang'])
        # audio_path = f"media/audio_line_{idx}.mp3"
        # tts.save(audio_path)

        # ğŸ”Š Google TTS ì‚¬ìš©
        audio_path = synthesize_speech(
            text=content,
            lang_code=voice_info['lang'],  # ì–¸ì–´ ì½”ë“œ
            gender=voice_info['gender'],
            voice_name=voice_info['voice'],
            
        )
        temp_audio_paths.append(audio_path)

        audio_clip = AudioFileClip(audio_path)
        audio_clips.append(audio_clip)

    # ğŸ”Š ì˜¤ë””ì˜¤ í´ë¦½ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸° (í•©ì¹˜ê¸° ì „ ì´ ê¸¸ì´ ê³„ì‚°)
    final_audio = concatenate_audioclips(audio_clips)
    total_audio_duration = final_audio.duration
    image_change_interval = total_audio_duration / len(image_paths)

    # ğŸï¸ ì˜ìƒ í´ë¦½ ìƒì„±
    elapsed_time = 0
    for idx, (line, audio_clip) in enumerate(zip(lines, audio_clips)):
        content = re.sub(r'^[A-Z]:\s*', '', line)  # ìë§‰ì—ì„œ í™”ì ì œê±°
        image_idx = int(elapsed_time // image_change_interval)
        image_idx = min(image_idx, len(image_paths) - 1)  # index overflow ë°©ì§€

        video_clip = create_slide_clip(
            content,
            image_path=image_paths[image_idx],
            duration=audio_clip.duration,
            font_size=font_size_to_points(font_size),
            font_color=font_color
        )
        clips.append(video_clip.set_duration(audio_clip.duration))
        elapsed_time += audio_clip.duration
 
    # ğŸ” ì˜¤ë””ì˜¤ì™€ ì˜ìƒ ê²°í•©
    final_video = concatenate_videoclips(clips, method="compose")
    final_video = final_video.set_duration(final_audio.duration).set_audio(final_audio)

    # ğŸ” ì˜ìƒ ê¸¸ì´ì™€ ì˜¤ë””ì˜¤ ê¸¸ì´ë¥¼ ê°•ì œë¡œ ì¼ì¹˜ì‹œí‚´
    final_video = final_video.set_duration(final_audio.duration).set_audio(final_audio)

    video_path = "media/final_video.mp4"
    final_video.write_videofile(
        video_path,
        fps=15,
        codec="libx264",
        audio_codec="aac",
        bitrate="1200k", 
        threads=4,
        preset="ultrafast",  # âœ… ë Œë”ë§ ì†ë„ ìµœìš°ì„ 
        temp_audiofile="media/temp-audio.m4a",  # ì„ì‹œ íŒŒì¼ ê²½ë¡œ ì§€ì •
        remove_temp=True,
    )

    print("âœ… ì˜ìƒ ìƒì„± ì™„ë£Œ!")

    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
    delete_temp_files()

    return video_path

# ê¸€ì í¬ê¸°ë¥¼ í¬ì¸íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
def font_size_to_points(size):
    if size == 'small':
        return 20
    elif size == 'medium':
        return 30
    elif size == 'large':
        return 40
    else:
        raise ValueError("Invalid font size")


            
